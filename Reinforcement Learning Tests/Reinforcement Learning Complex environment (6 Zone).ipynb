{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c68a21",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b3885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f1145",
   "metadata": {},
   "source": [
    "# Environment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd97e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported data taken from the robot's readings of the entire environment.\n",
    "\n",
    "data = [[103, 107, 130, 1638, 1200, 1181, 1183, 1210, 2550, 2138, 2151, 2193, 2550, 2550, 147, 121, 121, 143, 205, 130, 109], [103, 109, 128, 1654, 1219, 1189, 1183, 1202, 2550, 2435, 2151, 2550, 2550, 2550, 2550, 122, 122, 135, 156, 197, 112], [103, 112, 149, 1649, 1219, 1201, 1201, 1234, 2439, 2147, 2212, 2154, 2550, 2550, 122, 107, 103, 126, 191, 135, 112], [103, 109, 149, 1641, 1215, 1201, 1202, 1229, 2457, 2161, 2550, 2550, 2550, 2550, 121, 103, 103, 121, 145, 130, 109], [107, 118, 158, 1649, 1201, 1196, 1202, 1246, 2447, 2147, 2550, 2550, 2550, 2550, 118, 103, 109, 135, 195, 126, 112], [95, 94, 113, 1565, 877, 857, 855, 865, 1080, 1089, 103, 99, 113, 147, 474, 447, 443, 454, 490, 517, 103], [95, 101, 126, 1566, 871, 855, 857, 877, 939, 121, 103, 103, 121, 139, 464, 446, 446, 460, 496, 517, 101], [86, 93, 112, 1563, 871, 857, 861, 871, 2550, 137, 114, 112, 126, 154, 464, 447, 443, 455, 483, 121, 95], [84, 86, 113, 1563, 873, 857, 857, 872, 1098, 137, 114, 114, 130, 2550, 469, 447, 443, 455, 479, 534, 93], [84, 86, 114, 1557, 871, 857, 857, 873, 1196, 135, 113, 113, 135, 156, 464, 443, 443, 455, 496, 112, 86], [122, 121, 154, 599, 536, 515, 515, 532, 586, 1099, 1099, 1809, 2176, 909, 804, 788, 784, 796, 825, 1179, 130], [113, 122, 145, 582, 538, 519, 515, 534, 582, 1100, 1107, 1799, 2167, 909, 804, 780, 780, 794, 819, 804, 128], [112, 113, 138, 582, 542, 517, 517, 538, 578, 1105, 1115, 2155, 1337, 909, 800, 784, 778, 792, 878, 864, 118], [120, 120, 156, 580, 540, 518, 525, 542, 590, 1091, 1106, 2133, 1317, 835, 794, 778, 778, 788, 810, 164, 122], [118, 120, 147, 603, 551, 518, 525, 537, 597, 1113, 1107, 2138, 1330, 855, 796, 780, 773, 788, 810, 2550, 122], [455, 460, 479, 491, 536, 511, 511, 527, 572, 586, 856, 1513, 1808, 2550, 915, 109, 103, 122, 1173, 1173, 464], [460, 460, 491, 696, 532, 517, 517, 536, 578, 578, 856, 1787, 1528, 2550, 915, 107, 107, 122, 1196, 511, 464], [454, 455, 492, 726, 532, 517, 517, 534, 595, 595, 849, 1787, 1529, 2550, 915, 107, 107, 120, 1179, 1179, 460], [454, 456, 483, 706, 527, 517, 519, 540, 580, 580, 861, 1503, 1837, 2550, 1301, 103, 101, 120, 1179, 1179, 455], [454, 460, 483, 500, 544, 525, 525, 537, 597, 609, 853, 1490, 1830, 2550, 915, 101, 94, 114, 1166, 1173, 462], [95, 94, 118, 162, 122, 101, 101, 113, 2550, 1866, 1549, 1805, 2550, 2550, 483, 447, 443, 455, 500, 500, 99], [86, 93, 114, 164, 113, 99, 103, 122, 2550, 1848, 1823, 1809, 2550, 2550, 479, 447, 448, 464, 693, 2550, 95], [82, 86, 112, 164, 114, 94, 95, 118, 2550, 1611, 1835, 1821, 1808, 2550, 483, 454, 452, 460, 509, 2550, 91], [86, 93, 121, 156, 107, 93, 99, 128, 2550, 1650, 1825, 1805, 2550, 2550, 473, 454, 454, 469, 509, 114, 86], [94, 101, 126, 166, 112, 93, 94, 114, 2550, 1626, 1823, 1801, 2550, 2550, 483, 454, 454, 464, 706, 2550, 101], [428, 435, 464, 488, 454, 436, 439, 457, 506, 1866, 1829, 1876, 1885, 2550, 131, 107, 107, 120, 149, 454, 437], [427, 433, 469, 510, 454, 439, 439, 460, 500, 1856, 1825, 1841, 1876, 2550, 2550, 107, 103, 126, 490, 454, 433], [435, 439, 460, 518, 452, 437, 439, 460, 504, 1864, 1831, 1827, 1885, 2550, 2550, 109, 103, 122, 162, 462, 441], [439, 445, 483, 469, 445, 437, 437, 454, 502, 1830, 1817, 1843, 1862, 2550, 135, 112, 112, 126, 499, 464, 446], [439, 446, 475, 481, 447, 439, 439, 456, 527, 1852, 1823, 1831, 1864, 2550, 2550, 107, 107, 122, 848, 464, 445]]\n",
    "\n",
    "Zone_1 = [data[0], data[1], data[2], data[3], data[4]]\n",
    "Zone_2 = [data[5], data[6], data[7], data[8], data[9]]\n",
    "Zone_3 = [data[10], data[11], data[12], data[13], data[14]]\n",
    "Zone_4 = [data[15], data[16], data[17], data[18], data[19]]\n",
    "Zone_5 = [data[20], data[21], data[22], data[23], data[24]]\n",
    "Zone_6 = [data[25], data[26], data[27], data[28], data[29]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded229c1",
   "metadata": {},
   "source": [
    "# Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e776d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainZoneEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take: Guess 1 of 6 zones\n",
    "        self.action_space = Discrete(6)\n",
    "        #  array\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([5]))\n",
    "        # Set initial Zone Guess\n",
    "        self.state = 0\n",
    "        # Import the real Zone's sensor data\n",
    "        Zone = random.randint(0,5)\n",
    "        Num = 5*(Zone)\n",
    "        sample = data[Num]\n",
    "        self.sensor_data = sample\n",
    "        # Set amount of guesses per run\n",
    "        self.guess_length = 10\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Difine the sensor values for each Zone\n",
    "        sensor_zone = [Zone_1, Zone_2, Zone_3, Zone_4, Zone_5, Zone_6]\n",
    "        #apply the action\n",
    "        self.state = action\n",
    "        # Reduce guess length by 1\n",
    "        self.guess_length -= 1 \n",
    "        \n",
    "        # Calculate reward\n",
    "        # if the sensor data is in the chosen zone class, reward = 1\n",
    "        if self.sensor_data in sensor_zone[self.state]: \n",
    "            reward = 1\n",
    "            correct = True\n",
    "        else: \n",
    "            reward = -1\n",
    "            correct = False\n",
    "        \n",
    "        # Check if guessing is done\n",
    "        if self.guess_length <= 0 or correct == True: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset Initial Zone Guess\n",
    "        self.state = 0\n",
    "        # Import a new Zone's sensor data\n",
    "        Zone = random.randint(0,5)\n",
    "        Num = 5*(Zone)\n",
    "        sample = data[Num]\n",
    "        self.sensor_data = sample\n",
    "        # Reset Guess amount\n",
    "        self.guess_length = 10\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa40515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-1 Zone guess:4\n",
      "Episode:2 Score:-4 Zone guess:4\n",
      "Episode:3 Score:0 Zone guess:1\n",
      "Episode:4 Score:1 Zone guess:6\n",
      "Episode:5 Score:-3 Zone guess:6\n",
      "Episode:6 Score:0 Zone guess:3\n",
      "Episode:7 Score:0 Zone guess:2\n",
      "Episode:8 Score:-1 Zone guess:5\n",
      "Episode:9 Score:-10 Zone guess:2\n",
      "Episode:10 Score:1 Zone guess:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\gym\\spaces\\box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "env = TrainZoneEnv()\n",
    "\n",
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{} Zone guess:{}'.format(episode, score, n_state+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f907a6",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1126c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "\n",
    "def build_model(states, actions):\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(24, activation='relu', input_shape=states))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fe6c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10232/3682394117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef3c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                48        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 150       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 798\n",
      "Trainable params: 798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(states, actions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65b611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827ea25",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4182e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "\r",
      "    1/10000 [..............................] - ETA: 7:38 - reward: -1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 11 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40/10000 [..............................] - ETA: 2:11 - reward: -0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 12 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 13 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 14 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 15 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 16 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 17 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 18 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 19 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 20 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 21 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 22 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 23 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 24 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 25 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 26 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 27 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 28 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 29 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 30 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
      "C:\\Users\\Dylan\\anaconda3\\lib\\site-packages\\rl\\memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 31 + 1) instead\n",
      "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 55s 5ms/step - reward: -0.6666\n",
      "1991 episodes - episode_reward: -3.347 [-10.000, 1.000] - loss: 1.202 - mae: 2.216 - mean_q: -2.180\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 58s 6ms/step - reward: -0.6578\n",
      "2008 episodes - episode_reward: -3.274 [-10.000, 1.000] - loss: 1.311 - mae: 2.320 - mean_q: -2.332\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 60s 6ms/step - reward: -0.6392\n",
      "2098 episodes - episode_reward: -3.047 [-10.000, 1.000] - loss: 1.224 - mae: 2.206 - mean_q: -2.175\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 62s 6ms/step - reward: -0.6544\n",
      "2030 episodes - episode_reward: -3.223 [-10.000, 1.000] - loss: 1.255 - mae: 2.234 - mean_q: -2.211\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 63s 6ms/step - reward: -0.6360\n",
      "done, took 297.945 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x255e5e975b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6075586",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0152b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestZoneEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take: Guess 1 of 6 zones\n",
    "        self.action_space = Discrete(6)\n",
    "        #  array\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([5]))\n",
    "        # Set initial Zone Guess\n",
    "        self.state = 0\n",
    "        # Import the real Zone's sensor data\n",
    "        sample = data[Num]\n",
    "        self.sensor_data = sample\n",
    "        # Set amount of guesses per run\n",
    "        self.guess_length = 10\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Difine the sensor values for each Zone\n",
    "        sensor_zone = [Zone_1, Zone_2, Zone_3, Zone_4, Zone_5, Zone_6]\n",
    "        #apply the action\n",
    "        self.state = action\n",
    "        # Reduce guess length by 1\n",
    "        self.guess_length -= 1 \n",
    "        \n",
    "        # Calculate reward\n",
    "        # if the sensor data is in the chosen zone class, reward = 1\n",
    "        if self.sensor_data in sensor_zone[self.state]: \n",
    "            reward = 1\n",
    "            correct = True\n",
    "        else: \n",
    "            reward = -1\n",
    "            correct = False\n",
    "        \n",
    "        # Check if guessing is done\n",
    "        if self.guess_length <= 0 or correct == True: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset Initial Zone Guess\n",
    "        self.state = 0\n",
    "        # Import a new Zone's sensor data\n",
    "        sample = data[Num]\n",
    "        self.sensor_data = sample\n",
    "        # Reset Guess amount\n",
    "        self.guess_length = 10\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d059939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the zone the Agent is in.\n",
    "\n",
    "Zone = 1\n",
    "Num = 5*(Zone -1) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2221cec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 2 episodes ...\n",
      "Episode 1: reward: 0.000, steps: 2\n",
      "Episode 2: reward: 0.000, steps: 2\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Test to determine if the Agent knows where it is.\n",
    "env = TestZoneEnv()\n",
    "\n",
    "scores = dqn.test(env, nb_episodes=2, visualize=False)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
